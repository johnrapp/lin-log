---
title: "Project 2"
author: "Axel SjÃƒÂ¶berg & John Rapp Farnes"
date: "8 maj 2019"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 3
classoption: a4paper
---

```{r setup_knitr, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup_pdf, eval = FALSE}
# Install from CRAN
install.packages('rmarkdown')

# Render PDF
install.packages("tinytex")
tinytex::install_tinytex()  # install TinyTeX

```


```{r init_vars, include = FALSE}
library(ggplot2)
library(knitr)
library(dplyr)
library(rlist)
library(purrr)
library(pscl)

cdi <- read.delim("CDI.txt")
cdi$region <- factor(cdi$region, levels = c(1, 2, 3, 4),
                     labels = c("Northeast", "Midwest", "South", "West"))
cdi$crm1000 <- 1000 * cdi$crimes / cdi$popul

median = summary(cdi$crm1000)["Median"]

cdi <- cbind(cdi, hicrm = ifelse(cdi$crm1000 < median, 0, 1))
```

\newpage

# Introduction

In this paper we bla bla


# Analysis

## Predicting crime rate based on education level

### Seeing if there is relationship

We saw if there was a relationship by plotting bla bla with kernel smoother.


```{r code_plot, fig.width = 8, fig.height = 5, fig.cap = "Bla bla", fig.pos = "h", out.extra = ''}
with(cdi, {
   plot(hicrm ~ higrads)
   lines(ksmooth(higrads, hicrm, bandwidth = 20))
})

model.higrads <- glm(hicrm ~ higrads, data = cdi, family = "binomial")
sum <- summary(model.higrads)

x0 <- data.frame(higrads = seq(0, 100, 1))

predx <- cbind(x0, prob = predict(model.higrads, x0, type = "response"))
with(predx, lines(higrads, prob, col = "blue"))

# calculate conf.int for the linear part x*beta:
standard.error <- 1.96
xb <- predict(model.higrads, x0, se.fit = TRUE)
ci.xb <- data.frame(lwr = xb$fit - standard.error * xb$se.fit,
                    upr = xb$fit + standard.error * xb$se.fit)

# transform to CI for the odds:
ci.odds <- exp(ci.xb)

# and finally CI for the probabilities and add to the plot:
predx <- cbind(predx, ci.odds / (1 + ci.odds))
with(predx, {
  lines(higrads, lwr, lty = 2, col = "red")
  lines(higrads, upr, lty = 2, col = "red")
})

```

Seems to be relationship!

KOLLA UTAN BÖRJAN


### Confidence intervals and significance

Report the beta-estimates together with their confidence intervals and test whether the amount of adults with
12 years in school has a significant effect on the probability of having a higher than median crime rate


```{r beta_confidence}
to.prob = function(odds) {
  return (odds / (1 + odds))
}

coeff.beta <- model.higrads$coefficients

ci.beta <- suppressMessages(confint(model.higrads))

beta.p <- sum$coefficients[, "Pr(>|z|)"] * 100

table.beta.ci <- cbind("Estimate" = coeff.beta, ci.beta, "P-value (%)" = beta.p)
row.names(table.beta.ci) <- c("$\\beta_0$", "$\\beta_1$")

kable(table.beta.ci, caption = "Test", digits = 3)

```


Significance!

### Change in odds

Estimate the relative change in the odds (odds ratio) of having a high crime rate, with confidence interval,
when the amount of higrads is increased by 1 (percent), and when it is increased by 10 (percent).

```{r beta_decrease, include = F}
beta.higrads <- exp(coeff.beta["higrads"])

decrease.one.percent <- 1 - beta.higrads
decrease.ten.percent <- 1 - beta.higrads^10

display.percent <- function(value) {
  return(round(value * 100, digits=1))
}
```

If higrads increases 1%, odd decreases by `r display.percent(decrease.one.percent)`%
If higrads increases 10%, odd decreases by `r display.percent(decrease.ten.percent)`%


### Predict

Use the model to predict the probability, with confidence interval, of having a high crime rate in a county
where the amount of higrads is 65 (percent), and where it is 85 (percent).
```{r predict}
x0 <- data.frame(higrads = c(65, 85))


predx <- cbind(x0, prob = predict(model.higrads, x0, type = "response"))

standard.error <- 1.96
xb <- predict(model.higrads, x0, se.fit = TRUE)
ci.xb <- data.frame(lwr = xb$fit - standard.error * xb$se.fit,
                    upr = xb$fit + standard.error * xb$se.fit)
# transform to CI for the odds:
ci.odds <- exp(ci.xb)

# and finally CI for the probabilities and add to the plot:
predx <- cbind(predx, to.prob(ci.odds))

kable(predx, col.names = c("Higrads", "Probability", "2.5 %", "97.5 %"), caption = "Test")
```

Use the model to predict, for each of the counties, whether it would be expected to have a low or a high crime 
rate (predicted probability below or above 0.5) and calculate the sensitivity and specificity for this model.

Sensitivity is the proportion of the true successes that have been correctly classified as successes (true positive).
Specificity is the proportion of the true failures that have been correctly classified as failures (true negatives).


```{r pred_sense_spec, include = F}

pred.counties <- subset(cdi, select = c(county, higrads, hicrm))

pred.counties <- cbind(pred.counties, prob.hicrm = predict(model.higrads, pred.counties, type = "response"))
pred.counties <- cbind(pred.counties, pred.hicrm = ifelse(pred.counties$prob.hicrm > 0.5, 1, 0))

pred.counties

num.hicrm <- sum(pred.counties$hicrm)

# Sensitivity
true.postive <- with(pred.counties, ifelse(pred.hicrm == 1 & hicrm == 1, 1, 0))
sensitivity.higrads <- sum(true.postive) / num.hicrm
sensitivity.higrads

true.negative <- with(pred.counties, ifelse(pred.hicrm == 0 & hicrm == 0, 1, 0))
specificity.higrads <- sum(true.negative) / num.hicrm
specificity.higrads

```

Sensitivity was `r display.percent(sensitivity.higrads)`%

Specificity was `r display.percent(specificity.higrads)`%

## Predicting crime rate based on region

Make a cross-tabulation between region and hicrm. Choose as reference region in your regression models
the one that has the largest number of counties in it’s smallest low/high category. As a tie-breaker, use the
other low/high category. Why is this a good idea? Hint: look at how the standard errors for the log odds
(ratios) are calculated in this situation.

```{r cross_tabulation}

cross.table <- table(cdi %>% select(region, hicrm))

kable(cross.table, col.names = c("Low crime", "High crime"), caption = "Test")

reference.level <- "Northeast"

#prop.table(cross.table)
#prop.table(cross.table, 1)
#prop.table(cross.table, 2)

```

Set the reference level to `r reference.level`, makes sense to get low SE



Fit a logistic regression using region as (categorical) covariate and report the beta-estimates together with their
confidence intervals. Test whether there are any significant differences between the regions in the probability
of having a high crime rate.

```{r region_beta}
# Set reference
cdi$region <- relevel(cdi$region, ref = reference.level)

model.region <- glm(hicrm ~ region, data = cdi, family = "binomial")
sum <- summary(model.region)

coeff.beta <- model.region$coefficients

ci.beta <- suppressMessages(confint(model.region))

beta.p <- sum$coefficients[, "Pr(>|z|)"] * 100

table.beta.ci <- cbind("Estimate" = coeff.beta, ci.beta, "P-value (%)" = beta.p)
row.names(table.beta.ci) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$")

kable(table.beta.ci, caption = "Test", digits = 3)

```

Significant!


Estimate the odds ratios for having a high crime rate, with confidence interval, for the different regions,
compared to the reference region.



```{r beta_decreases}
beta.region <- exp(coeff.beta)

table.beta.ci <- cbind("OR" = exp(coeff.beta), exp(ci.beta))
table.beta.ci <- table.beta.ci[-c(1), ]
row.names(table.beta.ci) <- c("South", "Midwest", "West")

kable(table.beta.ci, caption = "Test", digits = 1)


```


Also estimate the probability of having a high crime rate, with confidence interval, for the different regions, including the reference region.


Calculate the sensitivity and specificity for this model. If we are allowed to have either higrads or region
as covariate, which one should we choose?


```{r pred_sense_spec2}

pred.counties <- subset(cdi, select = c(county, region, hicrm))

regions <- c("Northeast", "Midwest", "South", "West")

x0 <- data.frame(region = regions)

pred <- predict(model.region, x0, se.fit = TRUE, type = "response")


## confidence interval for log-odds
ci.prob <- cbind("2.5 %" = pred$fit - standard.error * pred$se.fit, 
                "97.5 %" = pred$fit + standard.error * pred$se.fit)


table.prob.ci <- cbind("Estimate" = pred$fit * 100, ci.prob * 100)
row.names(table.prob.ci) <- regions

kable(table.prob.ci, caption = "Test", digits = 1)


```

```{r pred_sense_spec3, include = F}

pred.counties <- subset(cdi, select = c(county, region, hicrm))

pred.counties <- cbind(pred.counties, prob.hicrm = predict(model.region, pred.counties, type = "response"))
pred.counties <- cbind(pred.counties, pred.hicrm = ifelse(pred.counties$prob.hicrm > 0.5, 1, 0))

pred.counties

num.hicrm <- sum(pred.counties$hicrm)

# Sensitivity
true.postive <- with(pred.counties, ifelse(pred.hicrm == 1 & hicrm == 1, 1, 0))
sensitivity.region <- sum(true.postive) / num.hicrm
sensitivity.region

true.negative <- with(pred.counties, ifelse(pred.hicrm == 0 & hicrm == 0, 1, 0))
specificity.region <- sum(true.negative) / num.hicrm
specificity.region

```

Sensitivity was `r display.percent(sensitivity.region)`%

Specificity was `r display.percent(specificity.region)`%

```{r pred_sense_spec4}

compare.sense <- data.frame(
  "Covariate" = c("Higrads", "Region"),
  "Sensitivity" = c(sensitivity.higrads, sensitivity.region),
  "Specificity" = c(specificity.higrads, specificity.region)
);
kable(compare.sense, caption = "Test", digits = 2)

```

Would prefer region

#ASD ASD

## Predicting crime rate based on region and higrads

Fit a third model using both higrads and region. For all three models, report their AIC, BIC, Nagelkerke
pseudo R^2, sensitivity and specificity. Which model is best?

```{r}
model.region.higrads <- glm(hicrm ~ higrads + region, data = cdi, family = "binomial")


model.names <- c("Higrads", "Region", "Both")
models <- list(model.higrads, model.region, model.region.higrads)

models

aic <- do.call(AIC, models)
#calc.aic <- AIC(models)

calc.aic <- do.call(AIC, models)$AIC
calc.bic <- do.call(AIC, c(models, list(k = log(nrow(cdi)))))$AIC
     
calc.metrics = function(model) {
  pred.counties <- cdi

  pred.counties <- cbind(pred.counties, prob.hicrm = predict(model, pred.counties, type = "response"))
  pred.counties <- cbind(pred.counties, pred.hicrm = ifelse(pred.counties$prob.hicrm > 0.5, 1, 0))
  
  num.hicrm <- sum(pred.counties$hicrm)
  
  # Sensitivity
  true.postive <- with(pred.counties, ifelse(pred.hicrm == 1 & hicrm == 1, 1, 0))
  sensitivity <- sum(true.postive) / num.hicrm
  sensitivity
  
  # Specificity
  true.negative <- with(pred.counties, ifelse(pred.hicrm == 0 & hicrm == 0, 1, 0))
  specificity <- sum(true.negative) / num.hicrm
  specificity
  
  metrics <- data.frame(
    sensitivity,
    specificity
  )
  
  return(metrics)
}

metrics <- sapply(models, calc.metrics)

#Pseudo R2
#R2.col <- t(cbind(pR2(model.higrads)[6], pR2(model.region)[6], pR2(model.region.higrads)[6]))
#colnames(R2.col)[colnames(R2.col)=="r2CU"] <- "Pseudo R2"

pseudo.R2 <- sapply(models, pR2)["r2CU",]

compare.models <- data.frame(
  model = model.names,
  aic = calc.aic,
  bic = calc.bic,
  sensitivity = unlist(metrics["sensitivity",]),
  specificity = unlist(metrics["specificity",]),
  PseudoR2 = pseudo.R2
)

compare.models
```



### Comparing models
```{r comparison_plot, fig.width = 8, fig.height = 5, fig.cap = "Bla bla", fig.pos = "h", out.extra = ''}

n <- nrow(compare.models)
x <- 1:n
with(compare.models, {
  par(mar = c(5, 4, 4, 4) + 0.3)  # Leave space for second axis
  
  plot(x, rep(0, n), type = "n", ylim = c(500, 650), xaxt = "n",
       ylab = "AIC/BIC", xlab = "Model",
       main = "Model comparison")
  axis(1, at = x, labels = model)
  lines(x, aic, col = "red", lty = 2, lwd = 2)
  lines(x, bic, col = "red", lty = 1, lwd = 2)
  
  par(new = TRUE)
  plot(x, rep(0, n), type = "n", axes = FALSE, ylim = c(0, 1), xaxt = "n",
     xlab = "", ylab = "")
  lines(x, PseudoR2, col = "blue", lty = 1, lwd = 2)
  best.model <- 3
  axis(side=4, at = pretty(c(0, 1)))
  mtext("Pseudo R2", side=4, line=3)
  
  legend("topright",legend=c("BIC", "AIC","Pseudo R2"),
    text.col=c("red","red", "blue"), lty=c(1, 2, 1),col=c("red","red", "blue"))
  
})

```

### Plot & skit
Use the third model and plot the squared standardized Pearson residuals and the standardized deviance residuals against the linear predictor x^beta. Is
there anything alarming here? Plot Cook’s distance against the linear predictor, as well as against higrads
and against region. Any interesting finds?

```{r}

#Likelihood ratio test:
(Ddiff <- model.region.higrads$null.deviance - model.region.higrads$deviance)
(dfdiff <- model.region.higrads$df.null - model.region.higrads$df.residual)
# .. or using the deviance table
anova(update(model.region.higrads, . ~ 1), model.region.higrads)
# chi2-quantile for comparison
qchisq(1 - 0.05, dfdiff)
# P-value for the test:
pchisq(Ddiff, dfdiff, lower.tail = FALSE)

```



### Interaction
One might suspect that the effect of higrads is different in different regions. Fit at fourth model adding the
interaction higrads * region to the third model, and use a Likelihood ratio test in order to determine
whether this is significantly better. Also calculate AIC, BIC, Nagelkerke, sensitivity and specificity and plot
the residuals and Cook’s distance. Do the interaction terms improve the model?

# Other variables
Find a better model using combinations of the variables higrads, region, poors and
phys1000 = 1000*phys/popul (see Lab 3). You may ignore interactions. Motivate why your model
is better.